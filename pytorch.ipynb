{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JSuCqJBqmoxn"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVpXPHBtALPX",
        "outputId": "a7d707cc-3000-4825-cfc3-eb2b71c0da4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3., 5.],\n",
              "        [1., 3., 4., 5.]])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t2 = torch.tensor([[1,2.,3,5.],[1,3,4.,5]])\n",
        "t2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUlcFSofAXv6",
        "outputId": "fbb4588d-30ea-4852-d367-b8abc26948ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t2.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNhNJnfpAZUg",
        "outputId": "1802ded8-2578-4a80-92bd-ee2082fb755c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 4])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqDtw9MaAcVE",
        "outputId": "bcb4a339-e351-48e1-bba0-be435e1d7d10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5, 7, 9])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([1,2,3])\n",
        "y = torch.tensor([4,5,6]) \n",
        "x + y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an_ZJ7ryEzEp",
        "outputId": "a427f466-d35f-4d79-9c9f-063b21ef7a9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 4, 10, 18])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x * y # performs elementwise operation btw two vectors of the same shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_2c8tbuEGkP"
      },
      "source": [
        "tensors have defined shapes that must be adhered to unlike a list of lists which can be of various sizes. Pytorch lets us compute the derivative of a tensor wrt to the tensors that have `requires_grad` set to `true`. Call `.backward()` on the tensor to compute the derivatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IBeshJpE3J4"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([1,2,3.,4,5], requires_grad=True)\n",
        "w = torch.tensor([.2,.3, .4, .5, .6], requires_grad=True)\n",
        "b = torch.tensor([0.1, 0.2, 0.1, 0.2, 0.3], requires_grad=True)\n",
        "\n",
        "y = torch.sum(x * w + b) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cbcbEtSFn3w",
        "outputId": "43800d80-69d7-482f-97c2-c34780683256"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dy/dx:  tensor([0.2000, 0.3000, 0.4000, 0.5000, 0.6000])\n",
            "dy/dw:  tensor([1., 2., 3., 4., 5.])\n",
            "dy/db:  tensor([1., 1., 1., 1., 1.])\n"
          ]
        }
      ],
      "source": [
        "y.backward() # can only be computed on scalars, not vectors\n",
        "print(\"dy/dx: \", x.grad)\n",
        "print(\"dy/dw: \", w.grad)\n",
        "print(\"dy/db: \", b.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_BEqACvF0UT"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_1ZzpOhGkHt"
      },
      "outputs": [],
      "source": [
        "x = np.array([1,2])\n",
        "x1 = torch.from_numpy(x) # uses same space in memory (no copy)\n",
        "x2 = torch.tensor(x) # creates a copy\n",
        "\n",
        "# tensor to numpy array using y.numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq_Og1rmHLGy"
      },
      "source": [
        "Torch is written to work well with GPUs unlike numpy on its own.\n",
        "\n",
        "Rarely have to loop over a tensor, there should always be a tensor operation you can use that vectorizes it, taking advantage of a gpu if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCI_Jmy3M6GY"
      },
      "outputs": [],
      "source": [
        "# general flow of a ml algo\n",
        "inputs = torch.tensor()\n",
        "targets = torch.tensor()\n",
        "\n",
        "w = torch.randn(2,3, requires_grad=True) # creates a 2 x 3 matrix with points randomly sampleded from a std normal distribution\n",
        "b = torch.randn(2, requires_grad=True) # creates a 2 element vector\n",
        "\n",
        "def model(x):\n",
        "  return x @ w.t() + b # .t() reutrns the transpose of a tensor and @ is used for matrix multiplication\n",
        "\n",
        "def mse(t1, t2):\n",
        "  diff = t1 - t2\n",
        "  return torch.sum(diff * diff) / diff.numel() # numel returns the number of elements in a tensor\n",
        "\n",
        "iterations = 1000\n",
        "learning_rate = 1e-5\n",
        "for i in range(iterations):\n",
        "  pred = model(inputs)\n",
        "  loss = mse(pred, target)\n",
        "  loss.backward()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "    b -= learning_rate * b.grad\n",
        "    \n",
        "    # have to zero the gradients before recomputing them b/c pytorch accumulates gradients by default \n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from utilities import train_model\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze all pretrained weights in model\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "# replace last layer for new classifier of 10 classes\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "trained_model = train_model(model, criterion, optimizer, num_epochs = 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Autograd demonstration\n",
        "a = torch.tensor([2.0, 3.0], requires_grad=True)\n",
        "b = torch.tensor([6.0, 4.0], requires_grad=True)\n",
        "\n",
        "Q = 3*a**3 - b**2\n",
        "\n",
        "external_grad = torch.tensor([1. , 1.])\n",
        "Q.backward(gradient=external_grad)\n",
        "\n",
        "assert 9*a**2 == a.grad\n",
        "assert -2*b == b.grad"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
